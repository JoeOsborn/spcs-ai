{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauey/spcs-ai/lib/python3.4/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='lasagne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataSet' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cc1dd45c0c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msubset_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataSet' object is not iterable"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = dataset['train']['X'][0].shape\n",
    "l_in = lasagne.layers.InputLayer(\n",
    "shape=(None, input_shape[0], input_shape[1], input_shape[2]))\n",
    "\n",
    "l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "l_in,\n",
    "    \n",
    "num_filters=32, filter_size=(5, 5),\n",
    "    \n",
    "nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    \n",
    "W=lasagne.init.HeNormal(gain='relu'))\n",
    "\n",
    "l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "\n",
    "l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "l_pool1, num_filters=32, filter_size=(5, 5),\n",
    "nonlinearity=lasagne.nonlinearities.rectify,\n",
    "W=lasagne.init.HeNormal(gain='relu'))\n",
    "l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))\n",
    "\n",
    "l_hidden1 = lasagne.layers.DenseLayer(\n",
    "l_pool2, num_units=256,\n",
    "nonlinearity=lasagne.nonlinearities.rectify,\n",
    "W=lasagne.init.HeNormal(gain='relu'))\n",
    "\n",
    "\n",
    "l_hidden1_dropout = lasagne.layers.DropoutLayer(l_hidden1, p=0.5)\n",
    "\n",
    "l_output = lasagne.layers.DenseLayer(\n",
    "l_hidden1_dropout,\n",
    "    \n",
    "num_units=10,\n",
    "nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_output = T.ivector('true_output')\n",
    "objective = lasagne.objectives.Objective(l_output,\n",
    "loss_function=lasagne.objectives.categorical_crossentropy)\n",
    "\n",
    "loss_train = objective.get_loss(target=true_output, deterministic=False)\n",
    "loss_eval = objective.get_loss(target=true_output, deterministic=True)\n",
    "all_params = lasagne.layers.get_all_params(l_output)\n",
    "\n",
    "updates = lasagne.updates.adadelta(loss_train, all_params)\n",
    "train = theano.function([l_in.input_var, true_output], loss_train, updates=updates)\n",
    "\n",
    "get_output = theano.function([l_in.input_var], l_output.get_output(deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 10\n",
    "\n",
    "batch_idx = 0\n",
    "\n",
    "epoch = 0\n",
    "while epoch < N_EPOCHS:\n",
    "    \n",
    "train(dataset['train']['X'][batch_idx:batch_idx + BATCH_SIZE],\n",
    "dataset['train']['y'][batch_idx:batch_idx + BATCH_SIZE])\n",
    "batch_idx += BATCH_SIZE\n",
    "\n",
    "if batch_idx >= dataset['train']['X'].shape[0]:\n",
    "    \n",
    "batch_idx = 0\n",
    "\n",
    "epoch += 1\n",
    "\n",
    "val_output = get_output(dataset['valid']['X'])\n",
    "\n",
    "val_predictions = np.argmax(val_output, axis=1)\n",
    "\n",
    "accuracy = np.mean(val_predictions == dataset['valid']['y'])\n",
    "print(\"Epoch {} validation accuracy: {}\".format(epoch, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
