{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform, choice\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_xys(xy_l_tuples,sz=15):\n",
    "    t_yes = [a[0] for a in xy_l_tuples if a[1] == 1]\n",
    "    t_no = [a[0] for a in xy_l_tuples if a[1] == 0]\n",
    "    plt.plot([x for (x,y) in t_yes],[y for (x,y) in t_yes],'go',markersize=sz)\n",
    "    plt.plot([x for (x,y) in t_no],[y for (x,y) in t_no],'ro',markersize=sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tuple_append(tpl,elt):\n",
    "    return tuple(list(tpl)+[elt])\n",
    "\n",
    "def perceptron(training, epochs):\n",
    "    # some parameters, maybe interesting to make these arguments\n",
    "    rate = 1.0\n",
    "    # how many weights do we need?\n",
    "    feature_count = len(training[0][0])\n",
    "    # pad each training example with a dummy 1 input\n",
    "    training = [(tuple_append(ins,1), label) for (ins,label) in training]\n",
    "    # initialize weights to random values\n",
    "    weights = [uniform(0,0.05) for _r in range(0,feature_count+1)]\n",
    "    # let's store the errors found during training\n",
    "    errors = []\n",
    "    for i in range(0,epochs):\n",
    "        # in each epoch, pick a subset of the training set (just one for now)\n",
    "        (example,actual) = choice(training)\n",
    "        # calculate the perceptron activation and the predicted category\n",
    "        # Note: You can use dot(vec1, vec2) to get the dot product between two sequential collections.\n",
    "        # calculate the error between predicted and actual and add it to errors\n",
    "        # update each weight according to the perceptron update rule\n",
    "    return (errors,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "and_set = [((0,0),0), ((0,1),0), ((1,0),0), ((1,1),1)]\n",
    "plot_xys(and_set)\n",
    "\n",
    "(errs,_) = perceptron(and_set,100)\n",
    "plt.figure()\n",
    "plt.plot(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "or_set = [((0,0),0), ((0,1),1), ((1,0),1), ((1,1),1)]\n",
    "plot_xys(or_set)\n",
    "\n",
    "(errs,_) = perceptron(or_set,100)\n",
    "plt.figure()\n",
    "plt.plot(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xor_set = [((0,0),0), ((0,1),1), ((1,0),1), ((1,1),0)]\n",
    "plot_xys(xor_set)\n",
    "\n",
    "(errs,_) = perceptron(xor_set,100)\n",
    "plt.figure()\n",
    "plt.plot(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noise_chance = 0.0\n",
    "N = 100\n",
    "xys = [(uniform(0,10),uniform(0,10)) for _r in range(0,N)]\n",
    "secret_f = lambda x: x*2 - 1\n",
    "dataset = [(xy,(1 if (secret_f(xy[0]) <= xy[1] or uniform(0,1)<noise_chance) else 0)) for xy in xys]\n",
    "plot_xys(dataset,5)\n",
    "\n",
    "trials = 1000\n",
    "(errs,weights) = perceptron(dataset,trials)\n",
    "plt.figure()\n",
    "plt.plot(errs)\n",
    "\n",
    "validation_N = 100\n",
    "# note the bounds here are a bit different, but we hope to generalize a bit from the training set\n",
    "val_xys = [(uniform(5,20),uniform(5,20)) for _r in range(0,validation_N)]\n",
    "validation = [(tuple_append(xy,1),(1 if secret_f(xy[0]) <= xy[1] else 0)) for xy in val_xys]\n",
    "val_net_error = 0\n",
    "for (example,actual) in validation:\n",
    "    # get the prediction based on the weights, calculate the (absolute) error and add it to the net error\n",
    "    pass\n",
    "val_error = val_net_error/len(validation)\n",
    "print(\"Validation error:\",val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
