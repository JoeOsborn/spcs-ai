Tay/Xiaoice from Microsoft

Xiaoice and Tay are both chatbots from Microsoft, although they have had varying degrees of success in the public eye. Xiaoice was launched in China in July of 2014 to simulate a 17 year old girl and has had great success. It was given a "personality" and "intelligence" by combing through the internet for Chinese conversations and learning from them. It is massively successful and has millions of users, even now. Some of its creators see it as a friend that is always available to talk to, and after being exposed to millions of people for so long they are quite happy with how it interacts with its users. 

Following the successs of Xiaoice, Microsoft decided to release another AI representing a teenage girl, this time based in the United States. This AI, named Tay, was contacted primarily through twitter but was taken down in the first 24 hours of its uptime because it started tweeting extremely offensive things. Microsoft put safeguards in place but they say Tay was specifically targeted by a group of people who worked around the safeguards and changed Tay's views. Since Tay was taken down, many people have deemed her a failure, but others view it as a success because we can learn from the mistakes that Microsoft made. 

Tay's behavior brings up a few issues in machine learning, one of which is a biased or less than ideal data set to learn from. Microsoft had trained Tay before releasing her, but she also needed to learn from the humans directly interacting with her, and many of these people were not good people to learn her values from. Tay had no sense of what is wrong or right, she simply repeats what she hears and learns how to respond from the people she interacts with. She is similar to a human child, except human children are taught by figures important to them (parents, etc.) what is wrong and what is right in order to have good morales. Tay did not have this conditioning and was therefore subject to the opinions of her peers, who in her case just wanted to make her say the most outrageous things possible.

Comparing the two chat bots, it can be presumed that Xiaoice and Tay both had similar conditioning and machine learning programming before being released, so what was the difference? Xiaoice is much more popular on personal messaging apps, where she has one on one conversations with millions of people, and learns from those individual conversations. Tay was more popular on Twitter, where more single messages are tweeted back and forth between people rather than full conversations. It is possible that Xiaoice became more compassionate and reasonable because she had more one on one converations, whereas people felt they could tweet anything at Tay, no matter how offensive. Tay was also specifically targeted by groups on the day of her release, meaning she did not have much time to learn before she was flooded with offenseive content. 

It seems that Tay needs more of a morale compass before she is let loose on the world, or just more time to develop before the world is let loose on her. The ironic part is that Tay was designed to imitate us, and yet we dissaprove of who she became. 

-Luke Mujica