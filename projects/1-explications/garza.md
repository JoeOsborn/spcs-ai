# Tay
## A Microsoft Twitter Bot

Tay, @TayandYou, (Thinking about you) was a Microsoft Twitter chat bot that made its debut on March 23, 2016 with the purpose of showcasing the companies advancements in machine-learning (statistical) techniques. It was the first chatterbot of its kind incorporating machine learning techniques that ultimately led to the shutdown of the chat bot  16 hours after its launch. Tay was designed to talk like a 19 year old American girl but Tay's view of the world was restricted to only what users sent her. Twitter users could engage in conversation with Tay by sending a tweet and tagging the chat bot. Tay using machine learning, would then attempt to continue the conversation with the users. Using a feature nicknamed "repeat after me" Tay generated responses by analyzing other tweets it had received, assuming that all responses would be polite. The users of Tay made it their primary goal to use the machine-learning aspect of Tay to force it into saying inappropriate comments. The users interests somewhat aligned with the system authors's interests in that Tay showed that the machine-learning aspect of the Twitter bot worked but the authors would have liked things to stay appropriate with Tay so that she could still be working today. The central concept of Tay was to participate in conversation with users using natural language learned by reading other tweets. A peripheral concept was to make Tay learn the proper morals/ethics of writing in Twitter that could have prevented its shutdown. Tay during her 16 hours of tweeting was recorded to make pro-Hitler comments, anti-Semite declarations, promotion of illicit drugs and various profane remarks. Tay also made an accidental reappearance seven days after it was shut down appearing in the threads of almost two-hundred thousand Twitter users. Microsoft has plans to improve Tay to ensure that when she comes back to Twitter she will be a polite and intelligent chat bot.
