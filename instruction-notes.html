<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Joseph C. Osborn" />
  <title>Schedule</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<div id="header">
<h1 class="title">Schedule</h1>
<h2 class="author">Joseph C. Osborn</h2>
</div>
<p>This document is intended for use by the instructor and TAs, since we don’t want to commit to a firm schedule or show the readings/assignments too far in advance (it might be confusing).</p>
<ul>
<li>Day 1: What is AI?
<ul>
<li><dl>
<dt>Reading</dt>
<dd>Before doing today’s assignment, students should read the excerpts from Philip Agre’s “Computation and Human Experience” as well as the D. Fox Harrell paper in the reader.
</dd>
</dl></li>
<li><dl>
<dt>Topic 1: What is AI?</dt>
<dd>Hi, who am I?
</dd>
<dd>Introduction to main threads of AI research. What is and is not AI. Historical and present uses of the term. AI winter. Sidestepping “what is ‘intelligence’”? Creative and commercial uses of AI. Generative methods. Modern AI as a set of techniques, rather than an attempt to simulate the brain. “Getting good results” vs “learning/claiming something about cognition”.
</dd>
<dd>(If possible, include some Game AI, some mixed initiative stuff (Tanagra), some of my research area here.)
<ul>
<li>Knowledge based</li>
<li>Grammars, logical systems, argumentation, social simulations, explicit representation of knowledge…</li>
<li>Expense, fragility, rhetorical purpose, …</li>
<li>Statistical</li>
<li>Genetic algorithms/programming, neural nets, machine learning …</li>
<li>Choice of loss function, metrics, overfitting, “money laundering for bias” …</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Exercise</dt>
<dd>Identify three “AI” systems. For each one, discuss and decide whether it is mainly knowledge-based or mainly statistical/machine-learning-based.
</dd>
</dl></li>
<li><dl>
<dt>Topic 2: Critical Technical Practice &amp; the Ethics of AI</dt>
<dd>Explanation of Agre’s and Harrell’s work. Examples from recent high-profile AI incidents including Microsoft’s “Tay” chatbot, noise-based attacks on Google’s image classifiers, MaxMind’s IP mapping, Facebook’s algorithmic feed emotion manipulation research, automated sentencing/parole…
</dd>
</dl></li>
<li>Topic 3: IPython. How to submit assignments. Q&amp;A.</li>
<li>What worked:
<ul>
<li>AI and ethics examples, group activity, pretty much every active learning segment got some response except “name some AI techniques”, ethics material.</li>
</ul></li>
<li>What didn’t work:
<ul>
<li>Arriving late (ugh), rushing through critical technical practice material.</li>
</ul></li>
<li>What to change for next time:
<ul>
<li>More active learning and student-driven exampling, less lecture, shorter reading addressed across more days.</li>
</ul></li>
<li><dl>
<dt>Assignment 1</dt>
<dd>Individual (short) assignment.
</dd>
</dl>
<p>Pick an AI system, describe it briefly, and explain its “perspective.” Who wrote this system and for what purpose? Who uses the system—are their goals aligned with those of the system authors? From a knowledge representation standpoint, how does it view the world? Which concepts are central, and which concepts are peripheral? How does this system interact with humans, and what does it know or assume about the humans who use it? How could a hostile user or third party subvert this system and break it or harrass/injure other users? Consult the documentation of this system, or articles written about it, if necessary. Write at least 300 words.</p>
<em>TAs could help students think of or explicate AI systems and draw out answers to these questions. Enterprising students could write more, engaging with the subject more deeply; or compare two or more different AI approaches to the same problem, with respect to the criteria above.</em></li>
<li><dl>
<dt>Assignment 2</dt>
<dd>Individual (short) assignment.
</dd>
</dl>
<p>Submit an IPython notebook with a Markdown cell briefly introducing yourself: your background in programming and/or AI, what you hope to gain from this course, and your favorite hobby or hobbies outside of programming (and even outside of computing).</p>
Also include a Python cell which prints out your name using the <code>print()</code> function.</li>
</ul></li>
<li>Day 2: Python, data structures, and algorithms
<ul>
<li>Topic 1: Building and processing interesting data structures
<ul>
<li>Get students to do the typing as much as possible</li>
<li>Python basics
<ul>
<li>Print each number between 1 and 10
<ul>
<li>for x in range</li>
</ul></li>
<li>Functions with ordered and keyword arguments</li>
<li>Draw an image in IPython</li>
<li>Random numbers</li>
</ul></li>
<li>Tuples, arrays, dicts
<ul>
<li>reverse a list, animal sounds</li>
<li>plot a graph in IPython</li>
<li>For x in y</li>
</ul></li>
<li>Classes
<ul>
<li>define and use custom objects</li>
<li>animal sounds 2—but don’t worry about inheritance for now, just polymorphism and info hiding</li>
</ul></li>
<li>Iterative functions (and stacks/queues/pointers)</li>
<li>Recursive functions (and accumulators)</li>
</ul></li>
<li>Topic 2: State machines and string recognizers
<ul>
<li>CS theory basics</li>
<li>Languages, intersection and union</li>
<li>Finite (word) automata</li>
<li>Deterministic vs nondeterministic</li>
<li>Extensions (symbolic FA, pushdown automata, counter automata, timed automata)</li>
<li>“Inspired by” (behavior trees, …)</li>
</ul></li>
<li>Exercise:
<ul>
<li>Pair up</li>
<li>Pick an agent from your experience (video game character, routine worker, animal, robot, …) and write out (possibly repetitive) sequences of actions they might perform (it’s okay to indicate cycles or similar with “…” or what-have-you) OR pick a string language and enumerate examples</li>
<li>What are the “letters”—basic actions—and what are the states?</li>
<li>Draw a state machine that captures that language of actions</li>
</ul></li>
<li>Topic 3: Graph traversal
<ul>
<li>(Quick: state machine implementation strategies)</li>
<li>Basic graph theory (trees)</li>
<li>Depth-first vs breadth-first
<ul>
<li>Ask for pseudocode (recursive AND iterative)</li>
</ul></li>
<li>Directed graphs, DAGs, and general graphs</li>
<li>Complications for depth- and breadth-first in presence of cycles
<ul>
<li>Ask for pseudocode (recursive AND iterative)</li>
</ul></li>
</ul></li>
<li>What worked:
<ul>
<li>State machine exercise. Many students knew Python already so that material was successful.</li>
</ul></li>
<li>What didn’t work:
<ul>
<li>Rushing through tree/graph material, not having a 100% prepared set of examples for Python learning.</li>
</ul></li>
<li>What to change for next time:
<ul>
<li>More active learning and student-driven exampling, a little less state machine theory material (save it for a subsequent day) and a little more tree/graph material, maybe even before the state machines.</li>
</ul></li>
<li><dl>
<dt>Assignment</dt>
<dd>Individual (short) assignment. Write two state machine evaluators for deterministic finite word automata: one which takes a state machine representing a language along with a string, and checks whether the machine accepts the string; and another which takes such a state machine and generates strings from it.
</dd>
</dl>
<em>We’ll provide the state machine data structures. Students with extra time could write a regular expression parser, or write functions to take the intersection or union of two languages, or visualize the evaluation steps using e.g. <code>pillow</code>.</em></li>
</ul></li>
<li>Day 3: Search and Planning
<ul>
<li>Reading
<ul>
<li>Red Blob Games’ <a href="http://www.redblobgames.com/pathfinding/a-star/introduction.html">A* tutorial</a></li>
<li>Excerpts from Sutton &amp; Barto’s reinforcement learning book <span class="citation">(1998)</span> (available <a href="https://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html">here</a>):
<ul>
<li>Sections 1.1–1.5</li>
<li>Section 2.1</li>
<li>Sections 3.1–3.3 (and as much of chapter 3 as you have time for)</li>
</ul></li>
<li>At least section 3 (“MONTE CARLO TREE SEARCH”) of Cameron Browne et al’s <a href="http://repository.essex.ac.uk/4117/1/MCTS-Survey.pdf">survey of MCTS methods</a></li>
</ul></li>
<li>Topic 1: Posing problems as graph search. Example: PuzzleGraph. Heuristic search (A*). Exploit/explore. Discrete constraint problems too (n-queens). Graph vs grid representations of space.
<ul>
<li>Recommend following the links from RedBlobGames’ tutorial as well.</li>
</ul></li>
<li>Exercise: Pair up. Pick an interesting problem and try to phrase it as “search” or planning. What are the operators at a given state? What are reward values at the end? Do operators have costs? Etc. Candidates include: transforming mathematical formulae, solving some logic puzzle, graph coloring, cooking…</li>
<li>Topic 2: MCTS, expected value, and backpropagation of reward
<ul>
<li>How do I calculate expected value?</li>
<li>Tree policy: How do I pick action? uniform random, weighted random, random among untried possibilities, … balancing exploit/explore</li>
<li>Default policy: How do I pick action? Want to explore as much as possible?</li>
<li>Backpropagation: max, decay, …</li>
</ul></li>
<li>Topic 3: Reinforcement learning: the problem, the basic idea, how it differs from MCTS (MCTS is a special case)
<ul>
<li>“MCTS estimates temporary state values in order to decide the next move, whereas TDL learns the long-term value of each state that then guides future behaviour”—mcts guesses more</li>
</ul></li>
<li>What worked:
<ul>
<li>Graph search, A* material, MCTS explanation, small-group activity</li>
</ul></li>
<li>What didn’t work:
<ul>
<li>RL material wasn’t prepared thoroughly enough</li>
<li>Maze should have been an immutable value object!</li>
</ul></li>
<li>What to change:
<ul>
<li>Needed more active learning opportunities, more specific RL material, too many different topics in one day (nobody had time to do enough reading).</li>
</ul></li>
<li><dl>
<dt>Assignment</dt>
<dd>Individual or pair (long) assignment. (1) should be done by tomorrow, (2) and (3) by Monday.
<ol style="list-style-type: decimal">
<li>Write a Python program to solve switch and door puzzles with one of the heuristic search algorithms described during the lecture. <em>(We’ll provide a Puzzle class and sample puzzles, and maybe a function to draw puzzles or solution paths to the console or an image?)</em> Try it on the provided sample puzzles; if some puzzles give your program trouble, try to explain why that happens.</li>
</ol>
</dd>
</dl>
<ol start="2" style="list-style-type: decimal">
<li><p>Once you have this working, write an agent which finds a policy for a “blind” puzzle using MCTS. “Blind” puzzles are just like the puzzles above, only (1) you don’t get to see the whole puzzle or know the goal states in advance, and (2) some nodes are trap doors with a chance of dropping the player into a bottomless pit! Try different policies for deciding between exploit/explore and for doing rollouts and compare them. <em>(We’ll provide a BlindPuzzle class and sample mazes, and maybe a function to draw mazes or maze paths to the console or an image?)</em></p></li>
<li><p>Do (2) but with reinforcement learning. Compare state-value vs action-value learning vs MCTS in terms of iterations required to reach a certain score, etc.</p></li>
</ol>
<em>(TAs could help with writing the code or understanding the algorithms. Eager students could implement multiple algorithms, select one on the fly, generate mazes, visualize the path-finding algorithms.)</em></li>
</ul></li>
<li>Day 4: Intro to probability and probabilistic programming
<ul>
<li><strong>Note: also need to do intermediate evaluations at the end of the day</strong></li>
<li>Topic 0: Feedback/notes on yesterday’s assignment
<ul>
<li>Ask the TAs for code to let you put Maze objects into sets or use them as keys in dicts. I meant to include that from the start. This lets you avoid tricks like turning the Maze into a string for this purpose.</li>
<li>NOTE: If you put a Maze into a set or use it as a dict key, don’t modify it at all afterwards (e.g. via <code>move_player</code>, <code>toggle</code>, or setting its variables)! Only clone it and change the clones—otherwise the set/dict will break in super confusing ways.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Should use <code>m.move_player()</code> and <code>m.toggle()</code> to modify game state and not e.g. check if <code>m.grid[y][x] == &quot;#&quot;</code></li>
<li>Since this is destructive, they should copy the maze using <code>m.clone()</code> before making a move</li>
<li>They can’t (easily) use a distance grid because switching switches changes which doors are open and closed, so player position doesn’t suffice to represent world state, so:</li>
<li>They need to track whether a maze has been seen before. One way is to use a set to track seen mazes.</li>
<li>They need to track the cost and predecessor state along with Maze states. Some ways of doing that include:
<ul>
<li>Add <code>cost</code> and <code>predecessor</code> properties to maze objects.</li>
<li>Include <code>cost</code> and <code>predecessor</code> with the maze in the frontier in a tuple. Of course, using priority queues the tuple’s first element should be <code>g(n) + h(n)</code> where <code>g(n)</code> is the real cost to reach node <code>n</code> and <code>h(n)</code> is the heuristic value (e.g. Manhattan distance from goal) at <code>n</code>.</li>
<li>Keep a <code>costs</code> dict and a <code>predecessors</code> dict or a <code>best_paths</code> dict keyed by Maze objects.</li>
</ul></li>
</ol></li>
<li>Topic 1: Basic probability/Bayes rule
<ul>
<li>what probability of an event means</li>
<li>P(X) – cases where X happens / all possible cases</li>
<li>P(X, Y) – cases where both X and Y happen / all possible cases</li>
<li>If X,Y independent, then P(X,Y) = P(X) P(Y)</li>
<li>P(X | Y) = P(Y|X) P(X) / P(Y) – or equivalently, P(Y,X) = P(X|Y) P(Y) / P(X)</li>
<li>Chaining: P(G,S,R)=P(G | S,R) P(S | R) P(R)</li>
<li>I like the <a href="https://en.wikipedia.org/wiki/Conditional_probability">wikipedia page</a> on conditional probability too</li>
<li>Bayesian statistics
<ul>
<li>Prior (background belief) and posterior (after considering prior) probability</li>
<li>Not, “What is the chance of X happening”, but “Given my background knowledge/superstition/experience, what is the chance of X happening?”</li>
<li>Example priors: Uniform/flat prior; or:
<ul>
<li>“An example is a prior distribution for the temperature at noon tomorrow. A reasonable approach is to make the prior a normal distribution with expected value equal to today’s noontime temperature, with variance equal to the day-to-day variance of atmospheric temperature, or a distribution of the temperature for that day of the year.”</li>
</ul></li>
<li>Priors are really important but we don’t have time to get too deeply into them</li>
</ul></li>
<li>Bayes nets</li>
<li>Given P(X | Y), P(X), and P(Y), we can find P(Y | X) with Bayes rule</li>
<li>P(X)=“Chance of rain”, P(Y)=“chance of clouds”: “Chance of rain when it’s cloudy = chance of clouds * chance of clouds given rain / chance of rain”</li>
<li>Bayes nets</li>
<li>Random variables and expected value
<ul>
<li>P(X=x)</li>
<li>“probability-weighted average of all possible values”</li>
</ul></li>
<li>Distributions (normal, poisson, negative binomial), mean/variance, and PDFs</li>
</ul></li>
<li>Exercise: Make a bayes net for some situation. It’s okay to use e.g. “low/medium/high” for the probabilities in the tables.</li>
<li>Topic 2: Probabilistic programming
<ul>
<li>Programming with distribution variables</li>
<li>“probabilistic programming languages extend a well-specified deterministic programming language with primitive constructs for random choice” <span class="citation">(Goodman and Stuhlmüller 2014)</span></li>
<li>“If we view the semantics of the underlying deterministic language as a map from programs to executions of the program, the semantics of a PPL built on it will be a map from programs to distributions over executions. When the program halts with probability one, this induces a proper distribution over return values.” <span class="citation">(Goodman and Stuhlmüller 2014)</span></li>
<li>WebPPL examples</li>
</ul></li>
<li>Topic 3: Let’s talk about projects
<ul>
<li>Project format</li>
<li>Project suggestions</li>
</ul></li>
<li>What went well:
<ul>
<li>Basic probability, Bayes nets and exercise, connection to ML, WebPPL</li>
</ul></li>
<li>What went poorly:
<ul>
<li>Bayes rule. Typo in my notes, stumbled, ended up with a result I couldn’t interpret well.</li>
</ul></li>
<li>What to do next time:
<ul>
<li>Should have practiced the Bayes Rule part of the lecture specifically!</li>
<li>Should have had more examples of belief nets in the bag.</li>
</ul></li>
<li><dl>
<dt>Assignment 1</dt>
<dd>Individual (small) assignment.
</dd>
</dl>
Give me a list of three or more project ideas you might be interested in doing, either from the suggestions or your own idea. If you have a partner or partners in mind, let me know as well. Submit them (as Markdown <code>.md</code> files) in the folder <code>projects/4-project-ideas</code>.</li>
<li><dl>
<dt>Assignment 2</dt>
<dd>Individual (small) assignment.
</dd>
</dl>
Fill out the preliminary evaluation form and send it to a TA. They’ll anonymize them and send them on to me so I can adjust the course based on your feedback. You can find the form in the <code>projects/4-evaluations</code> folder.</li>
<li>Assignment 3: MCTS and Reinforcement Learning agents for maze solving.</li>
<li><dl>
<dt>Assignment 4 (Optional)</dt>
<dd>Individual or pair (small) assignment.
</dd>
</dl>
<p>Make a probabilistic program expressing your Bayesian model from earlier today. Try to give it a prior based on your intuition, or by loading up a dataset. Either PyMC3 or WebPPL is fine.</p>
Submit it as an <code>.ipynb</code> or a <code>.wppl</code> file in <code>projects/4-probabilistic</code>.</li>
</ul></li>
<li>Day 5: Machine learning as function approximation
<ul>
<li>Topic 1: Error minimization and regression/gradient descent
<ul>
<li>Overfitting, linearity, curse of dimensionality …</li>
<li>Test set vs validation set, generalizing, overgeneralizing…</li>
</ul></li>
<li>Topic 2: Naive Bayes classifiers</li>
<li>Topic 3: Perceptrons</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Write a perceptron or simple NN, classify something. We’ll need to provide data sets!
</dd>
</dl></li>
</ul></li>
<li><dl>
<dt>Day 6: Deep Neural Networks</dt>
<dd><strong>Note: need to finalize projects</strong>
<ul>
<li><dl>
<dt>Reading</dt>
<dd>Primary sources on deep neural networks
</dd>
</dl></li>
<li>Topic 1: Deep neural networks (and intro to scikit-neuralnetwork)</li>
<li>Topic 2: Image recognition and convolution</li>
<li>Topic 3: Auto-encoders</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Write a image classifier or auto encoder?
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li>Day 7: Recurrent Neural Networks
<ul>
<li><em>Finalize project ideas by end of today! or tomorrow!</em></li>
<li><dl>
<dt>Reading</dt>
<dd>“The Unreasonable Effectiveness of RNNs” (Blog post)
</dd>
</dl></li>
<li>Topic 1: String-to-string translation</li>
<li>Topic 2: Style Transfer</li>
<li>Topic 3: Deep Reinforcement Learning</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Write a style transfer thing or string to string thing?
</dd>
</dl></li>
</ul></li>
<li>Day 8: Formal Logic &amp; Prolog Crash Course
<ul>
<li>Topic 1: Propositional logic and inference</li>
<li>Topic 2: Prolog and proof search. “Old school” symbolic AI stuff.</li>
<li>Topic 3: Knowledge bases</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Individual (medium-length) assignment.
</dd>
</dl>
Todo: Some kind of knowledge base or expert system… or a maze generator-cum-solver… or something that shows how much more compact Prolog programs can be than Python ones? Two part thing with one part today and one part Monday (day 10). Or some of the 99 prolog problems?</li>
</ul></li>
<li>Day 9: Creative AI
<ul>
<li><dl>
<dt>Reading</dt>
<dd>Generative Methods paper <span class="citation">(Compton, Osborn, and Mateas 2013)</span> and Kate’s PCG blog.
</dd>
</dl></li>
<li>Topic: What is creative AI? Intro to Tracery.</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Individual or pair (medium-length) assignment. Due Monday.
</dd>
</dl>
<p>Make a Tracery grammar to generate some interesting artifact: Genre stories, TV episodes, SVG images, Emoji compositions, musical leitmotifs, classified ads, inspirational quotes, fantasy game items, … and put up a Twitter bot with it. Go as far as you can with this.</p>
<em>Todo:elaborate.</em></li>
</ul></li>
<li>Day 10: Solving problems with logic
<ul>
<li>Topic 1: Planning with temporal logic and the event calculus. General game playing.</li>
<li>Topic 2: List/tree processing and meta-interpreters</li>
<li>Topic 3: DCGs?</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Individual or pair (short) assignment.
</dd>
<dd>symbolic manipulation stuff, NLP, …?
</dd>
</dl></li>
</ul></li>
<li>Day 11: Argumentation and Non-Monotonic Logics
<ul>
<li><dl>
<dt>Reading</dt>
<dd>At least Nute’s defeasible logic paper.
</dd>
</dl></li>
<li>Topic 1: Reasoning with exceptions; non-binary logic; defeasible logic, deontic logic, …</li>
<li>Topic 2: Reasoning about counterfactuals</li>
<li>Topic 3: Evaluating arguments</li>
<li><dl>
<dt>Assignment:</dt>
<dd>Individual (medium-length) assignment.
</dd>
</dl>
<p><em>Todo: clean up.</em></p>
<p>Encode some argumentation logic or legal thing or social thing or artistic thing or…</p>
Generate argument trees using a meta-interpreter and evaluate their quality. Provide a writeup describing your rationale and showing some example claims, arguments, and evaluations. There should be a couple of arguments generated for each claim so we (human readers) can see differences in the evaluations. If there’s no “subjectivity” in the argumentation, you’re probably not doing it right!</li>
</ul></li>
<li>Day 12: Project workshopping and research talk. Or more Prolog stuff, general game playing? Or other topics related to the projects?</li>
<li>Day 13: Presentations 1. New directions in AI.</li>
<li>Day 14: Presentations 2.</li>
</ul>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-compton2013generative">
<p>Compton, Kate, Joseph C Osborn, and Michael Mateas. 2013. “Generative Methods.” In <em>The Fourth Procedural Content Generation in Games Workshop, PCG</em>. Vol. 1.</p>
</div>
<div id="ref-dippl">
<p>Goodman, Noah D, and Andreas Stuhlmüller. 2014. “The Design and Implementation of Probabilistic Programming Languages.” <a href="http://dippl.org" class="uri">http://dippl.org</a>.</p>
</div>
<div id="ref-sutton1998reinforcement">
<p>Sutton, Richard S, and Andrew G Barto. 1998. <em>Reinforcement Learning: An Introduction</em>. Vol. 1. 1. MIT press Cambridge.</p>
</div>
</div>
</body>
</html>
